import torch
import torch.nn as nn
import torch.optim as optim
import numpy as np
import json
import time

# --- 1. ãƒ¢ãƒ‡ãƒ«å®šç¾© (Runtimeã¨åŒã˜æ§‹é€ ) ---
class WavePINN(nn.Module):
    def __init__(self, hidden_dim=64):
        super().__init__()
        # Padding=1 ã§ã‚µã‚¤ã‚ºã‚’å¤‰ãˆãªã„
        self.conv1 = nn.Conv1d(1, hidden_dim, kernel_size=3, padding=1)
        self.act1 = nn.Tanh()
        self.conv2 = nn.Conv1d(hidden_dim, hidden_dim, kernel_size=3, padding=1)
        self.act2 = nn.Tanh()
        self.head = nn.Conv1d(hidden_dim, 1, kernel_size=3, padding=1)

    def forward(self, x):
        x = self.act1(self.conv1(x))
        x = self.act2(self.conv2(x))
        return self.head(x)

# --- 2. ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ (1æ¬¡å…ƒæ³¢å‹•æ–¹ç¨‹å¼ã®è§£) ---
# ç›®æ¨™: u_tt = c^2 * u_xx ã‚’å­¦ç¿’ã•ã›ãŸã„ãŒã€
# MVPã§ã¯ã€Œå˜ç´”ãªç§»å‹•ï¼ˆAdvectionï¼‰ã€ã‚’å­¦ç¿’ã•ã›ã‚‹æ–¹ãŒç°¡å˜ã§ã€è¦‹ãŸç›®ã‚‚åˆ†ã‹ã‚Šã‚„ã™ã„ã§ã™ã€‚
# u(t+1, x) = u(t, x - c)  (å³ã«ãšã‚Œã‚‹ã ã‘)

def generate_training_data(batch_size=1000, seq_len=52):
    # ãƒ©ãƒ³ãƒ€ãƒ ãªæ³¢å½¢ã‚’ä½œã‚‹
    x = np.linspace(0, 10, seq_len)
    inputs = []
    targets = []
    
    for _ in range(batch_size):
        # ã‚¬ã‚¦ã‚¹ãƒ‘ãƒ«ã‚¹ã‚’ãƒ©ãƒ³ãƒ€ãƒ ãªä½ç½®ã«ç½®ã
        center = np.random.uniform(2, 8)
        width = np.random.uniform(0.5, 1.5)
        wave = np.exp(-(x - center)**2 / (2 * width**2))
        
        # å…¥åŠ›: ç¾åœ¨ã®æ³¢ u(t)
        inputs.append(wave)
        
        # æ­£è§£: å°‘ã—å³ã«ãšã‚ŒãŸæ³¢ u(t+1)
        # indexã§ã„ã†ã¨ 1ã¤å³ã¸ã‚·ãƒ•ãƒˆ (å·¦ç«¯ã¯0åŸ‹ã‚)
        shifted_wave = np.roll(wave, 1)
        shifted_wave[0] = 0 
        targets.append(shifted_wave)
        
    return torch.tensor(inputs, dtype=torch.float32).unsqueeze(1), \
           torch.tensor(targets, dtype=torch.float32).unsqueeze(1)

# --- 3. å­¦ç¿’ãƒ«ãƒ¼ãƒ— ---
def train_and_export():
    print("ğŸš€ Training started...")
    model = WavePINN(hidden_dim=64)
    optimizer = optim.Adam(model.parameters(), lr=0.005)
    criterion = nn.MSELoss()

    inputs, targets = generate_training_data(2000, 52)
    
    # 500 Epochå­¦ç¿’
    for epoch in range(500):
        optimizer.zero_grad()
        outputs = model(inputs)
        loss = criterion(outputs, targets)
        loss.backward()
        optimizer.step()
        
        if epoch % 50 == 0:
            print(f"Epoch {epoch}: Loss = {loss.item():.6f}")

    print("âœ… Training finished.")

    # --- 4. é‡ã¿ã®ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ (JSON) ---
    print("ğŸ“¦ Exporting weights...")
    weights = {
        "conv1_w": model.conv1.weight.detach().numpy().flatten().tolist(),
        "conv1_b": model.conv1.bias.detach().numpy().flatten().tolist(),
        "conv2_w": model.conv2.weight.detach().numpy().flatten().tolist(),
        "conv2_b": model.conv2.bias.detach().numpy().flatten().tolist(),
        "head_w":  model.head.weight.detach().numpy().flatten().tolist(),
        "head_b":  model.head.bias.detach().numpy().flatten().tolist(),
        "hidden_dim": 64
    }

    with open("wave_weights.json", "w") as f:
        json.dump(weights, f)
    print("âœ… wave_weights.json saved.")

if __name__ == "__main__":
    train_and_export()